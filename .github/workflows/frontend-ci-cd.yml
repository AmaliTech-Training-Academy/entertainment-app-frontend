name: CineVerse Frontend CI/CD

env:
  APP_NAME: 'entertainment-app-frontend'
  AWS_REGION: 'eu-west-1'
  TERRAFORM_VERSION: '1.9.8'
  NODE_VERSION: '18'

on:
  push:
    branches: [dev, staging, prod]
    paths: ['frontend/**', 'terraform/**', '.github/workflows/frontend-ci-cd.yml']
  pull_request:
    branches: [dev, staging, prod]
    paths: ['frontend/**', 'terraform/**']

jobs:
  # =============================================================================
  # Environment Configuration
  # =============================================================================
  setup:
    name: Setup Environment
    runs-on: self-hosted
    outputs:
      environment: ${{ steps.config.outputs.environment }}
      should_deploy: ${{ steps.config.outputs.should_deploy }}
      is_production: ${{ steps.config.outputs.is_production }}
    steps:
      - name: Configure Environment
        id: config
        run: |
          BRANCH="${{ github.ref_name }}"
          EVENT_NAME="${{ github.event_name }}"
          
          echo "Environment Detection:"
          echo "Branch: $BRANCH"
          echo "Event: $EVENT_NAME"
          
          # Set environment based on branch
          if [[ "$BRANCH" == "prod" ]]; then
            echo "environment=prod" >> $GITHUB_OUTPUT
            echo "is_production=true" >> $GITHUB_OUTPUT
            echo "Environment set to: prod (production)"
            ENV_NAME="prod"
          elif [[ "$BRANCH" == "staging" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
            echo "is_production=false" >> $GITHUB_OUTPUT
            echo "Environment set to: staging"
            ENV_NAME="staging"
          else
            echo "environment=dev" >> $GITHUB_OUTPUT
            echo "is_production=false" >> $GITHUB_OUTPUT
            echo "Environment set to: dev (default)"
            ENV_NAME="dev"
          fi
          
          # Only deploy on push to main branches
          if [[ "$EVENT_NAME" == "push" && "$BRANCH" =~ ^(dev|staging|prod)$ ]]; then
            echo "should_deploy=true" >> $GITHUB_OUTPUT
            echo "Deployment enabled for push to $BRANCH"
            SHOULD_DEPLOY="true"
          else
            echo "should_deploy=false" >> $GITHUB_OUTPUT
            echo "Deployment disabled (event: $EVENT_NAME, branch: $BRANCH)"
            SHOULD_DEPLOY="false"
          fi
          
          echo ""
          echo "Final Configuration:"
          echo "Environment: $ENV_NAME"
          echo "Should Deploy: $SHOULD_DEPLOY"
          echo "Is Production: $([ "$BRANCH" == "prod" ] && echo "true" || echo "false")"

  # =============================================================================
  # Security Scanning
  # =============================================================================
  security:
    name: Security Scan
    runs-on: self-hosted
    needs: setup
    if: always()
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install Dependencies
        working-directory: frontend
        run: npm ci

      - name: NPM Security Audit
        working-directory: frontend
        run: |
          npm audit --audit-level=moderate --json > npm-audit-report.json || true
          npm audit --audit-level=moderate
        continue-on-error: false

      - name: Terraform Security Scan
        uses: aquasecurity/tfsec-action@v1.0.0
        with:
          working_directory: terraform/
          format: sarif
          soft_fail: true

      - name: Upload Security Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports-${{ github.sha }}
          path: frontend/npm-audit-report.json
          retention-days: 30

  # =============================================================================
  # Build and Test
  # =============================================================================
  build:
    name: Build & Test
    runs-on: self-hosted
    needs: [setup]
    if: always()
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install Dependencies
        working-directory: frontend
        run: npm ci

      # - name: Run Linter
      #   working-directory: frontend
      #   run: |
      #     npm run lint
  
      # Install Chromium browser, which is necessary for Karma to run tests in a headless environment
      - name: Install Chromium for Headless Tests
        run: sudo apt-get update && sudo apt-get install -y chromium-browser

      # Run Angular tests with a headless Chrome browser
      # CHROME_BIN environment variable points Karma to the correct Chromium executable
      # '--no-watch' prevents Karma from watching files for changes (not needed in CI)
      # '--browsers=ChromeHeadless' explicitly tells Karma to use the headless Chrome browser
      - name: Run Frontend Tests
        working-directory: frontend
        env:
          CHROME_BIN: /usr/bin/chromium-browser
        run: |
          npm test -- --no-watch --browsers=ChromeHeadless
        continue-on-error: true

      - name: Create Environment Files
        working-directory: frontend/src/environments
        run: |
          ENV="${{ needs.setup.outputs.environment }}"
          
          # Create base environment file
          cat > environment.ts << 'EOF'
          export const environment = {
            production: false,
            apiUrl: 'http://localhost:3000/api'
          };
          EOF
          
          # Create environment-specific files
          case "$ENV" in
            "dev")
              cat > environment.dev.ts << 'EOF'
          export const environment = {
            production: false,
            apiUrl: 'https://api-dev.cineverse.com/api'
          };
          EOF
              ;;
            "staging")
              cat > environment.staging.ts << 'EOF'
          export const environment = {
            production: false,
            apiUrl: 'https://api-staging.cineverse.com/api'
          };
          EOF
              ;;
            "prod")
              cat > environment.prod.ts << 'EOF'
          export const environment = {
            production: true,
            apiUrl: 'https://api.cineverse.com/api'
          };
          EOF
              ;;
          esac

      - name: Build Application
        working-directory: frontend
        run: |
          ENV="${{ needs.setup.outputs.environment }}"
          echo "Building for environment: $ENV"
          
          case "$ENV" in
            "dev")     npm run build -- --configuration=development ;;
            "staging") npm run build -- --configuration=staging ;;
            "prod")    npm run build -- --configuration=production ;;
            *)         echo "Unknown environment: $ENV" && exit 1 ;;
          esac
          
          echo "Build completed successfully"
          
          # Verify build output
          if [ -d "dist/${{ env.APP_NAME }}" ]; then
            echo "Build output found in dist/${{ env.APP_NAME }}"
            ls -la "dist/${{ env.APP_NAME }}"
          else
            echo "Build output not found"
            ls -la dist/
            exit 1
          fi


      - name: Upload Build Artifact
        uses: actions/upload-artifact@v4
        with:
          name: frontend-build-${{ needs.setup.outputs.environment }}
          path: frontend/dist/${{ env.APP_NAME }}
          retention-days: 7

  # =============================================================================
  # Infrastructure Planning
  # =============================================================================
  plan:
    name: Infrastructure Plan
    runs-on: self-hosted
    needs: [setup, build]
    if: always() && needs.build.result == 'success'
    env:
      ENVIRONMENT: ${{ needs.setup.outputs.environment }}
    outputs:
      plan_changes: ${{ steps.plan.outputs.plan_changes }}
      plan_exitcode: ${{ steps.plan.outputs.plan_exitcode }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Debug Environment
        run: |
          echo "Plan Job Environment Debug:"
          echo "ENVIRONMENT (from env): $ENVIRONMENT"
          echo "setup.outputs.environment: ${{ needs.setup.outputs.environment }}"
          echo "github.ref_name: ${{ github.ref_name }}"
          echo "should_deploy: ${{ needs.setup.outputs.should_deploy }}"
          echo "is_production: ${{ needs.setup.outputs.is_production }}"
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Create Environment Configuration
        working-directory: terraform
        run: |
          echo "Creating configuration for environment: $ENVIRONMENT"
          mkdir -p environments/$ENVIRONMENT
          
          # Create backend configuration
          cat > environments/$ENVIRONMENT/backend.hcl << EOF
          bucket         = "cineverse-terraform-state-$ENVIRONMENT"
          key            = "frontend/$ENVIRONMENT/terraform.tfstate"
          region         = "${{ env.AWS_REGION }}"
          encrypt        = true
          dynamodb_table = "cineverse-terraform-locks"
          EOF
          
          # Determine WAF setting based on environment
          if [[ "$ENVIRONMENT" == "dev" ]]; then
            WAF_ENABLED="false"
            DOMAIN_NAME='""'
          else
            WAF_ENABLED="true"
            DOMAIN_NAME='"'$ENVIRONMENT'.cineverse.com"'
          fi
          
          echo "WAF Enabled: $WAF_ENABLED"
          echo "Domain Name: $DOMAIN_NAME"
          
          # Create terraform variables
          cat > environments/$ENVIRONMENT/terraform.tfvars << EOF
          environment      = "$ENVIRONMENT"
          project_name     = "cineverse"
          aws_region       = "${{ env.AWS_REGION }}"
          enable_waf       = $WAF_ENABLED
          enable_monitoring = true
          
          # Domain configuration
          domain_name = $DOMAIN_NAME
          
          # API endpoint
          api_endpoint = "https://api-$ENVIRONMENT.cineverse.com"
          EOF
          
          echo "Created terraform.tfvars:"
          cat environments/$ENVIRONMENT/terraform.tfvars
          
          echo ""
          echo "Created backend.hcl:"
          cat environments/$ENVIRONMENT/backend.hcl

      - name: Terraform Init & Validate
        working-directory: terraform
        run: |
          echo "Initializing Terraform for environment: $ENVIRONMENT"
          
          terraform init -backend-config="environments/$ENVIRONMENT/backend.hcl" || {
            echo "Terraform init failed. Checking S3 bucket and DynamoDB table..."
            aws s3 ls s3://cineverse-terraform-state-$ENVIRONMENT || echo "S3 bucket cineverse-terraform-state-$ENVIRONMENT not found"
            aws dynamodb describe-table --table-name cineverse-terraform-locks --region ${{ env.AWS_REGION }} || echo "DynamoDB table cineverse-terraform-locks not found"
            exit 1
          }
          
          terraform validate
          
          # Show current state summary
          RESOURCE_COUNT=$(terraform state list 2>/dev/null | wc -l || echo 0)
          echo "Current state contains $RESOURCE_COUNT resources"
          
          if [[ $RESOURCE_COUNT -gt 0 ]]; then
            echo "Current resources in state:"
            terraform state list | head -10
            if [[ $RESOURCE_COUNT -gt 10 ]]; then
              echo "... and $((RESOURCE_COUNT - 10)) more"
            fi
          fi

      - name: Force Unlock Terraform State
        working-directory: terraform
        run: |
          echo "Checking for existing state locks..."
          
          # Capture plan output to check for lock
          PLAN_OUTPUT=$(terraform plan -var-file="environments/$ENVIRONMENT/terraform.tfvars" -detailed-exitcode 2>&1 || true)
          PLAN_EXIT_CODE=$?
          
          if [[ $PLAN_EXIT_CODE -eq 2 && "$PLAN_OUTPUT" =~ "Lock Info" ]]; then
            echo "State appears to be locked. Attempting to force unlock..."
            LOCK_ID=$(echo "$PLAN_OUTPUT" | grep -oE 'ID:[[:space:]]*[a-f0-9-]{36}' | awk '{print $2}')
            if [[ -n "$LOCK_ID" ]]; then
              echo "Force unlocking with ID: $LOCK_ID"
              terraform force-unlock -force "$LOCK_ID" || echo "Force unlock failed or not needed"
            else
              echo "Could not extract lock ID"
            fi
          else
            echo "No state lock detected or plan failed for other reasons"
          fi

      - name: Terraform Plan
        id: plan
        working-directory: terraform
        run: |
          echo "Creating Terraform plan for environment: $ENVIRONMENT"
          
          # Set tags via environment variables
          export TF_VAR_tags='{
            "Environment": "'$ENVIRONMENT'",
            "Project": "CineVerse",
            "ManagedBy": "Terraform",
            "Branch": "${{ github.ref_name }}",
            "CommitSHA": "${{ github.sha }}",
            "DeployedBy": "${{ github.actor }}",
            "DeployedAt": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"
          }'
          
          # Check if state file exists and has resources
          RESOURCE_COUNT=$(terraform state list 2>/dev/null | wc -l || echo 0)
          echo "Current state contains $RESOURCE_COUNT resources"
          
          terraform plan \
            -var-file="environments/$ENVIRONMENT/terraform.tfvars" \
            -out="$ENVIRONMENT.tfplan" \
            -detailed-exitcode
          
          PLAN_EXIT_CODE=$?
          echo "plan_exitcode=$PLAN_EXIT_CODE" >> $GITHUB_OUTPUT
          
          if [[ $RESOURCE_COUNT -eq 0 ]]; then
            echo "State is empty - forcing plan creation for initial deployment"
            echo "plan_changes=true" >> $GITHUB_OUTPUT
          elif [[ $PLAN_EXIT_CODE -eq 0 ]]; then
            echo "No changes needed - infrastructure is up to date"
            echo "plan_changes=false" >> $GITHUB_OUTPUT
          elif [[ $PLAN_EXIT_CODE -eq 1 ]]; then
            echo "Terraform plan failed"
            echo "plan_changes=error" >> $GITHUB_OUTPUT
            exit 1
          elif [[ $PLAN_EXIT_CODE -eq 2 ]]; then
            echo "Changes detected - plan created successfully"
            echo "plan_changes=true" >> $GITHUB_OUTPUT
          fi
          
          # Verify plan file exists
          if [[ -f "$ENVIRONMENT.tfplan" ]]; then
            echo "Plan file created: $ENVIRONMENT.tfplan"
          else
            echo "WARNING: Plan file $ENVIRONMENT.tfplan not created"
          fi

      - name: Upload Terraform Plan
        uses: actions/upload-artifact@v4
        if: steps.plan.outputs.plan_changes == 'true'
        with:
          name: terraform-plan-${{ env.ENVIRONMENT }}
          path: terraform/${{ env.ENVIRONMENT }}.tfplan
          retention-days: 7

  # =============================================================================
  # Deployment
  # =============================================================================
  deploy:
    name: Deploy to ${{ needs.setup.outputs.environment }}
    runs-on: self-hosted
    needs: [setup, plan]
    if: needs.setup.outputs.should_deploy == 'true' && needs.plan.result == 'success'
    environment: ${{ needs.setup.outputs.environment }}
    env:
      ENVIRONMENT: ${{ needs.setup.outputs.environment }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Recreate Environment Configuration
        working-directory: terraform
        run: |
          echo "Recreating configuration for environment: $ENVIRONMENT"
          mkdir -p environments/$ENVIRONMENT
          
          # Recreate backend configuration
          cat > environments/$ENVIRONMENT/backend.hcl << EOF
          bucket         = "cineverse-terraform-state-$ENVIRONMENT"
          key            = "frontend/$ENVIRONMENT/terraform.tfstate"
          region         = "${{ env.AWS_REGION }}"
          encrypt        = true
          dynamodb_table = "cineverse-terraform-locks"
          EOF
          
          # Determine WAF setting based on environment
          if [[ "$ENVIRONMENT" == "dev" ]]; then
            WAF_ENABLED="false"
            DOMAIN_NAME='""'
          else
            WAF_ENABLED="true"
            DOMAIN_NAME='"'$ENVIRONMENT'.cineverse.com"'
          fi
          
          # Recreate terraform variables
          cat > environments/$ENVIRONMENT/terraform.tfvars << EOF
          environment      = "$ENVIRONMENT"
          project_name     = "cineverse"
          aws_region       = "${{ env.AWS_REGION }}"
          enable_waf       = $WAF_ENABLED
          enable_monitoring = true
          
          # Domain configuration
          domain_name = $DOMAIN_NAME
          
          # API endpoint
          api_endpoint = "https://api-$ENVIRONMENT.cineverse.com"
          EOF
          
          echo "Created terraform.tfvars:"
          cat environments/$ENVIRONMENT/terraform.tfvars
          
          echo ""
          echo "Created backend.hcl:"
          cat environments/$ENVIRONMENT/backend.hcl

      - name: Terraform Init
        working-directory: terraform
        run: |
          echo "Initializing Terraform for environment: $ENVIRONMENT"
          terraform init -backend-config="environments/$ENVIRONMENT/backend.hcl" || {
            echo "Terraform init failed. Checking S3 bucket and DynamoDB table..."
            aws s3 ls s3://cineverse-terraform-state-$ENVIRONMENT || echo "S3 bucket cineverse-terraform-state-$ENVIRONMENT not found"
            aws dynamodb describe-table --table-name cineverse-terraform-locks --region ${{ env.AWS_REGION }} || echo "DynamoDB table cineverse-terraform-locks not found"
            exit 1
          }

      - name: Download Terraform Plan
        uses: actions/download-artifact@v4
        if: needs.plan.outputs.plan_changes == 'true'
        continue-on-error: false
        with:
          name: terraform-plan-${{ env.ENVIRONMENT }}
          path: terraform/

      - name: Debug Infrastructure State
        working-directory: terraform
        run: |
          echo "=== Infrastructure State Analysis ==="
          
          echo "1. Terraform version and workspace:"
          terraform version
          terraform workspace show
          
          echo ""
          echo "2. Configuration files:"
          ls -la *.tf
          
          echo ""
          echo "3. Module directories:"
          ls -la modules/ 2>/dev/null || echo "No modules directory found"
          if [ -d "modules" ]; then
            find modules/ -name "*.tf" | head -10
          fi
          
          echo ""
          echo "4. Checking for existing state:"
          # Check if state file exists in S3 backend
          if terraform state list >/dev/null 2>&1; then
            echo "✓ State file exists in S3 backend"
            RESOURCE_COUNT=$(terraform state list | wc -l)
            echo "Total resources in state: $RESOURCE_COUNT"
            
            if [[ $RESOURCE_COUNT -gt 0 ]]; then
              echo "Current resources in state:"
              terraform state list | head -10
              
              echo ""
              echo "Resources by type:"
              terraform state list | cut -d. -f1 | sort | uniq -c
              
              echo ""
              echo "Module resources:"
              terraform state list | grep "^module\." | sort || echo "No module resources found"
            else
              echo "State file exists but contains no resources"
            fi
          else
            echo "✓ No state file found - this is a first-time deployment"
            echo "Will create infrastructure from scratch"
          fi
          
          echo ""
          echo "5. Validating terraform configuration:"
          terraform validate
          
          echo ""
          echo "6. Checking current outputs (if any):"
          terraform output -json 2>/dev/null || echo "No outputs available (expected for first deployment)"

      - name: Determine Deployment Strategy
        id: strategy
        working-directory: terraform
        run: |
          echo "=== Determining Deployment Strategy ==="
          
          # Check if this is a first-time deployment
          if terraform state list >/dev/null 2>&1; then
            RESOURCE_COUNT=$(terraform state list | wc -l)
            echo "Found existing state with $RESOURCE_COUNT resources"
            
            if [[ $RESOURCE_COUNT -eq 0 ]]; then
              echo "deployment_type=first_time" >> $GITHUB_OUTPUT
              echo "Strategy: First-time deployment (empty state)"
            elif [[ $RESOURCE_COUNT -eq 1 ]]; then
              echo "deployment_type=broken_state" >> $GITHUB_OUTPUT
              echo "Strategy: Broken state cleanup and rebuild"
            else
              echo "deployment_type=update" >> $GITHUB_OUTPUT
              echo "Strategy: Update existing infrastructure"
            fi
          else
            echo "deployment_type=first_time" >> $GITHUB_OUTPUT
            echo "Strategy: First-time deployment (no state)"
          fi
          
          echo ""
          echo "Plan changes from previous step: ${{ needs.plan.outputs.plan_changes }}"
          echo "Plan file exists: $([[ -f '$ENVIRONMENT.tfplan' ]] && echo 'yes' || echo 'no')"

      - name: Clean Broken State (if needed)
        if: steps.strategy.outputs.deployment_type == 'broken_state'
        working-directory: terraform
        run: |
          echo "=== Cleaning Broken State ==="
          
          echo "Current resource in state:"
          terraform state list
          
          # Check if this is a random_string resource (circular dependency indicator)
          if terraform state list | grep -q "random_string"; then
            echo "Found random_string resource - indicates circular dependency issue"
            echo "Removing problematic resource from state..."
            
            terraform state list | grep "random_string" | xargs -I {} terraform state rm {}
            
            echo "State after cleanup:"
            terraform state list || echo "State is now empty"
          else
            echo "Found unexpected single resource - will proceed with caution"
          fi

      - name: Apply Infrastructure Changes
        working-directory: terraform
        run: |
          echo "=== Applying Infrastructure Changes ==="
          
          # Set tags via environment variables
          export TF_VAR_tags='{
            "Environment": "'$ENVIRONMENT'",
            "Project": "CineVerse", 
            "ManagedBy": "Terraform",
            "Branch": "${{ github.ref_name }}",
            "CommitSHA": "${{ github.sha }}",
            "DeployedBy": "${{ github.actor }}",
            "DeployedAt": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"
          }'
          
          DEPLOYMENT_TYPE="${{ steps.strategy.outputs.deployment_type }}"
          echo "Deployment type: $DEPLOYMENT_TYPE"
          
          case "$DEPLOYMENT_TYPE" in
            "first_time")
              echo " First-time deployment - creating all resources"
              terraform apply -auto-approve -var-file="environments/$ENVIRONMENT/terraform.tfvars"
              ;;
            "broken_state")
              echo " Broken state detected - rebuilding infrastructure"
              terraform apply -auto-approve -var-file="environments/$ENVIRONMENT/terraform.tfvars"
              ;;
            "update")
              if [[ "${{ needs.plan.outputs.plan_changes }}" == "true" && -f "$ENVIRONMENT.tfplan" ]]; then
                echo " Applying planned changes"
                terraform apply -auto-approve "$ENVIRONMENT.tfplan"
              elif [[ "${{ needs.plan.outputs.plan_changes }}" == "false" ]]; then
                echo " No changes needed - infrastructure is up to date"
              else
                echo " Applying changes without existing plan"
                terraform apply -auto-approve -var-file="environments/$ENVIRONMENT/terraform.tfvars"
              fi
              ;;
            *)
              echo " Unknown deployment type: $DEPLOYMENT_TYPE"
              exit 1
              ;;
          esac
          
          echo ""
          echo "=== Verifying Deployment Results ==="
          
          # Check final state
          if terraform state list >/dev/null 2>&1; then
            FINAL_RESOURCE_COUNT=$(terraform state list | wc -l)
            echo "✓ Final state contains $FINAL_RESOURCE_COUNT resources"
            
            if [[ $FINAL_RESOURCE_COUNT -eq 0 ]]; then
              echo " ERROR: No resources created!"
              exit 1
            elif [[ $FINAL_RESOURCE_COUNT -lt 5 ]]; then
              echo "  WARNING: Expected more resources. Current resources:"
              terraform state list
              echo "This might indicate a partial deployment"
            else
              echo " Infrastructure deployment appears successful"
            fi
          else
            echo " ERROR: State file still not found after apply"
            exit 1
          fi
          
          echo ""
          echo "=== Refreshing Outputs ==="
          terraform refresh -var-file="environments/$ENVIRONMENT/terraform.tfvars" -input=false
          
          echo "Available outputs:"
          terraform output -json || echo "No outputs available"

      - name: Get Infrastructure Outputs
        id: outputs
        working-directory: terraform
        run: |
          echo "=== Extracting Infrastructure Outputs ==="
          
          # Wait a moment for state to stabilize
          sleep 5
          
          # Method 1: Try normal terraform outputs
          echo "1. Attempting normal terraform outputs..."
          if terraform output -json > outputs.json 2>/dev/null && [ -s outputs.json ] && [ "$(cat outputs.json)" != "{}" ]; then
            echo "✓ Normal terraform outputs available"
            
            S3_BUCKET=$(terraform output -raw s3_bucket_name 2>/dev/null || echo "")
            CF_ID=$(terraform output -raw cloudfront_distribution_id 2>/dev/null || echo "")
            CF_DOMAIN=$(terraform output -raw cloudfront_domain_name 2>/dev/null || echo "")
            
            if [ -n "$S3_BUCKET" ] && [ -n "$CF_ID" ] && [ -n "$CF_DOMAIN" ]; then
              echo " Successfully extracted all outputs via terraform output"
              echo "S3 Bucket: $S3_BUCKET"
              echo "CloudFront ID: $CF_ID"
              echo "CloudFront Domain: $CF_DOMAIN"
            else
              echo "  Some outputs missing from terraform output, falling back to state extraction"
              S3_BUCKET=""
              CF_ID=""
              CF_DOMAIN=""
            fi
          else
            echo "  Terraform outputs not available, extracting from state..."
            S3_BUCKET=""
            CF_ID=""
            CF_DOMAIN=""
          fi
          
          # Method 2: Extract from state if outputs failed
          if [ -z "$S3_BUCKET" ] || [ -z "$CF_ID" ] || [ -z "$CF_DOMAIN" ]; then
            echo ""
            echo "2. Extracting from terraform state..."
            
            # Extract S3 bucket
            if [ -z "$S3_BUCKET" ]; then
              S3_RESOURCE=$(terraform state list | grep "module.s3_website.aws_s3_bucket.website" | head -1)
              if [ -n "$S3_RESOURCE" ]; then
                S3_BUCKET=$(terraform state show "$S3_RESOURCE" | grep -E "^\s*id\s*=" | cut -d'"' -f2)
                echo "✓ Extracted S3 bucket from state: $S3_BUCKET"
              fi
            fi
            
            # Extract CloudFront distribution
            if [ -z "$CF_ID" ] || [ -z "$CF_DOMAIN" ]; then
              CF_RESOURCE=$(terraform state list | grep "module.cloudfront.aws_cloudfront_distribution.website" | head -1)
              if [ -n "$CF_RESOURCE" ]; then
                if [ -z "$CF_ID" ]; then
                  CF_ID=$(terraform state show "$CF_RESOURCE" | grep -E "^\s*id\s*=" | cut -d'"' -f2)
                  echo "✓ Extracted CloudFront ID from state: $CF_ID"
                fi
                if [ -z "$CF_DOMAIN" ]; then
                  CF_DOMAIN=$(terraform state show "$CF_RESOURCE" | grep -E "^\s*domain_name\s*=" | cut -d'"' -f2)
                  echo "✓ Extracted CloudFront domain from state: $CF_DOMAIN"
                fi
              fi
            fi
          fi
          
          # Method 3: Final validation and error handling
          echo ""
          echo "3. Final validation..."
          
          if [ -z "$S3_BUCKET" ]; then
            echo " ERROR: Could not extract S3 bucket name"
            echo "Available S3 resources:"
            terraform state list | grep s3 || echo "No S3 resources found"
            exit 1
          fi
          
          if [ -z "$CF_ID" ]; then
            echo " ERROR: Could not extract CloudFront distribution ID"
            echo "Available CloudFront resources:"
            terraform state list | grep cloudfront || echo "No CloudFront resources found"
            exit 1
          fi
          
          if [ -z "$CF_DOMAIN" ]; then
            echo " ERROR: Could not extract CloudFront domain name"
            echo "Available CloudFront resources:"
            terraform state list | grep cloudfront || echo "No CloudFront resources found"
            exit 1
          fi
          
          echo ""
          echo " Successfully extracted all infrastructure outputs:"
          echo "   S3 Bucket: $S3_BUCKET"
          echo "   CloudFront ID: $CF_ID"
          echo "   CloudFront Domain: $CF_DOMAIN"
          
          # Set outputs for next steps
          echo "s3_bucket=$S3_BUCKET" >> $GITHUB_OUTPUT
          echo "cloudfront_id=$CF_ID" >> $GITHUB_OUTPUT
          echo "cloudfront_domain=$CF_DOMAIN" >> $GITHUB_OUTPUT

      - name: Download Build Artifact
        uses: actions/download-artifact@v4
        with:
          name: frontend-build-${{ env.ENVIRONMENT }}
          path: build

      - name: Deploy to S3
        run: |
          S3_BUCKET="${{ steps.outputs.outputs.s3_bucket }}"
          
          echo "Deploying to S3 bucket: $S3_BUCKET"
          
          # Verify build contents
          echo "Build contents:"
          ls -la build/
          
          # For Angular SSR, the client files are in browser/ subdirectory
          if [ -d "build/browser" ]; then
            echo "Angular SSR detected - deploying from browser/ directory"
            DEPLOY_PATH="build/browser"
          elif [ -f "build/index.html" ]; then
            echo "Standard Angular build detected"
            DEPLOY_PATH="build"
          else
            echo "ERROR: Neither build/browser nor build/index.html found!"
            echo "Available directories:"
            find build/ -type d
            echo "Available files:"
            find build/ -name "*.html"
            exit 1
          fi
          
          echo "Deploying from: $DEPLOY_PATH"
          echo "Contents of deploy directory:"
          ls -la "$DEPLOY_PATH"
          
          # Verify index.html exists in deploy path
          if [ ! -f "$DEPLOY_PATH/index.html" ]; then
            echo "ERROR: index.html not found in $DEPLOY_PATH"
            exit 1
          fi
          
          # Deploy with appropriate cache headers
          echo "Syncing files to S3..."
          
          # First sync: everything except HTML/JS/CSS with long cache
          aws s3 sync "$DEPLOY_PATH/" s3://$S3_BUCKET/ --delete \
            --cache-control "public, max-age=31536000" \
            --exclude "*.html" --exclude "*.js" --exclude "*.css"
          
          # Second sync: HTML/JS/CSS with short cache
          aws s3 sync "$DEPLOY_PATH/" s3://$S3_BUCKET/ --delete \
            --cache-control "public, max-age=0, must-revalidate" \
            --include "*.html" --include "*.js" --include "*.css"
          
          # Verify files were uploaded correctly
          echo "Files uploaded to S3:"
          aws s3 ls s3://$S3_BUCKET/ --recursive | head -20
          
          # Verify index.html is in root
          if aws s3 ls s3://$S3_BUCKET/index.html; then
            echo "index.html successfully uploaded to S3 root"
          else
            echo "index.html not found in S3 root!"
            exit 1
          fi

      - name: Invalidate CloudFront Cache
        if: ${{ steps.outputs.outputs.cloudfront_id != '' && success() }}
        run: |
          CLOUDFRONT_ID="${{ steps.outputs.outputs.cloudfront_id }}"
          
          if [[ -z "$CLOUDFRONT_ID" || "$CLOUDFRONT_ID" == ::error::* ]]; then
            echo "Invalid CloudFront ID. Skipping invalidation."
            exit 0
          fi

          echo "Invalidating CloudFront distribution: $CLOUDFRONT_ID"

          INVALIDATION_ID=$(aws cloudfront create-invalidation \
            --distribution-id "$CLOUDFRONT_ID" \
            --paths "/*" \
            --query 'Invalidation.Id' \
            --output text)

          echo "Cache invalidation created: $INVALIDATION_ID"
      - name: Verify Deployment
        run: |
          echo "Waiting for deployment to propagate..."
          sleep 30
          
          DOMAIN="${{ steps.outputs.outputs.cloudfront_domain }}"
          echo "Testing deployment at: https://$DOMAIN"
          
          RESPONSE_CODE=$(curl -s -o /dev/null -w "%{http_code}" https://$DOMAIN)
          
          if [[ "$RESPONSE_CODE" == "200" ]]; then
            echo " Application is responding correctly (HTTP $RESPONSE_CODE)"
          else
            echo "  Application returned HTTP $RESPONSE_CODE (may need propagation time)"
          fi

      - name: Deployment Summary
        run: |
          cat << EOF >> $GITHUB_STEP_SUMMARY
          #  Deployment Successful
          
          **Environment:** $ENVIRONMENT  
          **Application URL:** https://${{ steps.outputs.outputs.cloudfront_domain }}  
          **S3 Bucket:** ${{ steps.outputs.outputs.s3_bucket }}  
          **CloudFront ID:** ${{ steps.outputs.outputs.cloudfront_id }}  
          **Branch:** ${{ github.ref_name }}  
          **Commit:** ${{ github.sha }}  
          **Deployed by:** ${{ github.actor }}
          **Deployment Type:** ${{ steps.strategy.outputs.deployment_type }}
          EOF


  # =============================================================================
  # Auto-Merge Staging to Prod (with Manual Approval)
  # =============================================================================
  auto-merge-staging-to-prod:
    name: Auto-Merge Staging to Prod
    runs-on: self-hosted
    needs: [deploy] # This job runs after the 'deploy' job completes
    # Only run this job if the 'deploy' job was for the 'staging' environment and was successful
    if: github.ref == 'refs/heads/staging' && needs.deploy.result == 'success'
    
    permissions:
      contents: write # Required to push changes
      pull-requests: write # Required to create and merge pull requests

    steps:
      - name: Checkout Staging Branch
        uses: actions/checkout@v4
        with:
          ref: staging # Checkout the staging branch
          token: ${{ secrets.GITHUB_TOKEN }} # Use default GITHUB_TOKEN for repo write access

      - name: Configure Git
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"

      - name: Create Pull Request to Prod
        id: cpr # Added ID to reference outputs
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "Merge staging into prod after successful staging deployment"
          title: "Release: Merge Staging to Production"
          body: |
            This pull request automatically merges the `staging` branch into `prod`
            after a successful deployment to the staging environment.
            
            **Reviewers: Please approve this PR to initiate the production deployment.**
          branch: auto-merge/staging-to-prod-${{ github.run_id }} # Unique branch name for the PR
          base: prod # Target branch for the PR
          delete-branch: true # Delete the temporary branch after merge
          # Removed: auto-merge: true

      - name: Enable Auto-Merge on PR
        # Only run if a PR was successfully created
        if: steps.cpr.outputs.pull-request-number != ''
        run: |
          PR_NUMBER="${{ steps.cpr.outputs.pull-request-number }}"
          REPO_OWNER="${{ github.repository_owner }}"
          REPO_NAME="${{ github.event.repository.name }}"
          
          echo "Enabling auto-merge for PR #$PR_NUMBER on $REPO_OWNER/$REPO_NAME"
          
          # Use GitHub CLI (gh) if available, otherwise curl
          # Using gh CLI is often simpler and more robust
          if command -v gh &> /dev/null; then
            gh pr merge "$PR_NUMBER" --auto --squash # Or --merge, --rebase depending on your merge strategy
            echo "Auto-merge enabled via GitHub CLI."
          else
            # Fallback to curl if gh CLI is not available
            echo "GitHub CLI not found, falling back to curl for auto-merge."
            curl -L \
              -X PATCH \
              -H "Accept: application/vnd.github+json" \
              -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
              -H "X-GitHub-Api-Version: 2022-11-28" \
              "https://api.github.com/repos/$REPO_OWNER/$REPO_NAME/pulls/$PR_NUMBER" \
              -d '{"auto_merge": true}'
            echo "Auto-merge request sent via curl."
          fi

      - name: Notify Auto-Merge PR Created
        run: echo "Successfully created auto-merge PR from staging to prod. Awaiting manual approval on prod environment."
